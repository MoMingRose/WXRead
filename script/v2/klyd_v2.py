# -*- coding: utf-8 -*-
# klyd_v2.py created by MoMingLog on 1/4/2024.
"""
ã€ä½œè€…ã€‘MoMingLog
ã€åˆ›å»ºæ—¶é—´ã€‘2024-04-01
ã€åŠŸèƒ½æè¿°ã€‘
"""
import json
import random
import re
import sys
import time

from httpx import URL

from config import load_klyd_config
from exception.common import PauseReadingWaitNext, StopReadingNotExit, CookieExpired, RspAPIChanged, ExitWithCodeChange, \
    FailedPushTooManyTimes, NoSuchArticle
from exception.klyd import FailedPassDetect, \
    RegExpError, WithdrawFailed
from schema.klyd import KLYDConfig, RspRecommend, RspReadUrl, RspDoRead, ArticleInfo, RspWithdrawal, RspWithdrawalUser
from script.common.base import WxReadTaskBase, RetTypes
from utils import EntryUrl, md5
from utils.logger_utils import NestedLogColors


class APIS:
    # è·å–æ¨èä¿¡æ¯
    RECOMMEND = "/tuijian"
    # è·å–é˜…è¯»é“¾æ¥
    GET_READ_URL = "/new/get_read_url"
    # è·å–æç°ç”¨æˆ·ä¿¡æ¯
    WITHDRAWAL = "/withdrawal"
    # å¼€å§‹è¿›è¡Œæç°
    DO_WITHDRAWAL = "/withdrawal/doWithdraw"


class KLYDV2(WxReadTaskBase):
    CURRENT_SCRIPT_VERSION = "2.0.0"
    CURRENT_TASK_NAME = "å¯ä¹é˜…è¯»"

    # å½“å‰è„šæœ¬åˆ›å»ºæ—¶é—´
    CURRENT_SCRIPT_CREATED = "2024-03-30"
    # å½“å‰è„šæœ¬æ›´æ–°æ—¶é—´
    CURRENT_SCRIPT_UPDATED = "2024-04-02"

    CURRENT_R_JS_VERSION = "5"

    R_JS_CODE_MD5 = "726fd4cbecf02fb665a489882a7721b2"

    # æå–æ­£åœ¨åŠ è½½é¡µé¢æºä»£ç ä¸­çš„å†…å®¹
    # å½“å‰æå–çš„æ˜¯forstrã€zsã€iuã€url(éƒ¨åˆ†)ã€r.js
    READ_LOAD_PAGE_COMPILE = re.compile(
        r"script.*?forstr\s*=\s*['\"](.*?)['\"];.*?zs\s*=\s*['\"](.*?)['\"];.*?iu\s*=\s*['\"](.*?)['\"];.*?\s*=\s*['\"](https?.*?)['\"].*?['\"](.*?)['\"].*?src=['\"](.*?\?v=(\d+))['\"]",
        re.S)
    R_JS_CODE_COMPILE = re.compile(
        r"var\s*url\s=\s['\"](.*?)['\"].*?['\"](.*?)['\"]",
        re.S
    )
    # æ£€æµ‹æœ‰æ•ˆé˜…è¯»é“¾æ¥
    ARTICLE_LINK_VALID_COMPILE = re.compile(
        r"^https?://mp.weixin.qq.com/s\?__biz=[^&]*&mid=[^&]*&idx=\d*&(?!.*?chksm).*?&scene=\d*#wechat_redirect$")
    # æ–‡ç« æ ‡é¢˜
    ARTICLE_TITLE_COMPILE = re.compile(r'meta.*?og:title"\scontent="(.*?)"\s*/>', re.S)
    # æ–‡ç« ä½œè€…
    ARTICLE_AUTHOR_COMPILE = re.compile(r'meta.*?og:article:author"\scontent="(.*?)"\s*/>', re.S)
    # æ–‡ç« æè¿°
    ARTICLE_DESC_COMPILE = re.compile(r'meta.*?og:description"\scontent="(.*?)"\s*/>', re.S)
    # æ–‡ç« Biz
    ARTICLE_BIZ_COMPILE = re.compile(r"og:url.*?__biz=(.*?)&", re.S)

    def __init__(self, config_data: KLYDConfig = load_klyd_config()):
        self.detected_biz_data = config_data.biz_data
        self.base_full_url = None
        # self.exclusive_url = config_data.exclusive_url
        super().__init__(config_data=config_data, logger_name="ğŸ¥¤é˜…è¯»")

    def get_entry_url(self):
        return EntryUrl.get_klrd_entry_url()[0]

    def init_fields(self):
        first_redirect_url: URL = self.__request_entry_for_redirect()
        self.base_url = f"{first_redirect_url.scheme}://{first_redirect_url.host}"
        self.base_full_url = first_redirect_url

    def run(self, name):

        self.base_client.base_url = self.base_url
        self.logger.info(f"å¼€å§‹æ‰§è¡Œ{NestedLogColors.red(name)}çš„ä»»åŠ¡")
        homepage_url: URL = self.__request_redirect_for_redirect()
        self.logger.debug(f"homepage_urlï¼š{homepage_url}")

        # è§‚çœ‹æŠ“åŒ…æ•°æ®æµï¼Œè²Œä¼¼ä¸‹æ–¹çš„è¯·æ±‚å¯æœ‰å¯æ— ï¼Œæ— æ‰€è°“ï¼Œåˆ¤æ–­ä¸€ä¸‹ä¹Ÿå¥½
        homepage_html, status = self.request_for_page(
            homepage_url,
            "è¯·æ±‚é¦–é¡µæºä»£ç  base_client",
            client=self.base_client,
            ret_types=RetTypes.STATUS
        )
        if status == 302:
            # å¦‚æœæ˜¯é‡å®šå‘çš„å“åº”ï¼Œåˆ™æœ‰å¯èƒ½æ˜¯cookieè¿‡æœŸäº†
            # ä¸ºäº†é¿å…ä¸å¿…è¦çš„è¯·æ±‚, è¿™é‡Œç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä»è€Œåœæ­¢å½“å‰è¿™ä¸ªç”¨æˆ·çš„æ‰§è¡Œçº¿ç¨‹
            raise CookieExpired()
        # å†å¤šä¸€å±‚åˆ¤æ–­ï¼Œä»¥é˜²ä¸‡ä¸€
        if 'f9839ced92845cbf6166b0cf577035d3' != md5(homepage_html):
            raise ExitWithCodeChange("homepage_html")

        self.is_need_withdraw = False
        try:
            # è·å–æ¨èæ•°æ®ï¼ˆé‡Œé¢åŒ…å«å½“å‰é˜…è¯»çš„ä¿¡æ¯ï¼‰
            recommend_data = self.__request_recommend_json(homepage_url)
            self.__print_recommend_data(recommend_data)
            # è·å–åŠ è½½é¡µé¢è·³è½¬é“¾æ¥
            self.load_page_url: URL = self.__request_for_read_url()
            self.logger.info(f"è·å–åŠ è½½é¡µé“¾æ¥æˆåŠŸ: {self.load_page_url}")
            # è·å–åŠ è½½é¡µé¢æºä»£ç 
            read_load_page_html: str = self.__request_for_read_load_page(self.load_page_url)
            forstr, zs, r_js_path, r_js_version = self.__parse_read_load_page(read_load_page_html)
            self.logger.debug(f"r_js_pathï¼š{r_js_path}")
            self.logger.debug(f"r_js_versionï¼š{r_js_version}")
            if self.CURRENT_R_JS_VERSION != r_js_version:
                raise ExitWithCodeChange("r_js_version")
            # è®¾ç½®read_clientçš„base_url
            self.read_client.base_url = f"{self.load_page_url.scheme}://{self.load_page_url.host}"
            r_js_code = self.__request_r_js_code(r_js_path)
            if self.R_JS_CODE_MD5 != md5(r_js_code):
                raise ExitWithCodeChange("r_js_code")
            # è§£æå®Œæˆé˜…è¯»çš„é“¾æ¥
            do_read_url_part_path = self.__parse_r_js_code(r_js_code, forstr, zs)
            do_read_url_full_path = self.__build_do_read_url_path(do_read_url_part_path)
            # å°è¯•é€šè¿‡æ£€æµ‹å¹¶ä¸”å¼€å§‹é˜…è¯»
            self.__pass_detect_and_read(do_read_url_part_path, do_read_url_full_path)
            # å°è¯•è¿›è¡Œæç°æ“ä½œ
            self.__request_withdraw()
            self.is_need_withdraw = False
        except FailedPushTooManyTimes as e:
            self.logger.war(e)
            self.is_need_withdraw = False
            sys.exit(0)
        except (FailedPassDetect, WithdrawFailed, NoSuchArticle) as e:
            self.logger.war(e)
            self.is_need_withdraw = False
        finally:
            if self.is_need_withdraw:
                self.__request_withdraw()

    def __request_withdraw(self):
        """
        å‘èµ·æç°è¯·æ±‚
        :return:
        """

        # å…ˆè·å–è¦è¿›è¡Œæç°çš„ç”¨æˆ·ä¿¡æ¯
        withdrawal_model: RspWithdrawal | dict = self.__request_withdrawal_for_userinfo()
        # åˆ¤æ–­æ•°æ®æ¨¡å‹æ˜¯å¦éªŒè¯æˆåŠŸ
        if isinstance(withdrawal_model, RspWithdrawal):
            # è·å–ç”¨æˆ·ä¿¡æ¯
            withdrawal_user_info: RspWithdrawalUser = withdrawal_model.data.user
            # æ‰“å°ç”¨æˆ·ä¿¡æ¯
            self.logger.info(withdrawal_user_info)
            amount = withdrawal_user_info.amount
            u_ali_account = withdrawal_user_info.u_ali_account
            u_ali_real_name = withdrawal_user_info.u_ali_real_name
        else:
            user_info = withdrawal_model.get("data", {}).get("user")
            if user_info is None:
                raise RspAPIChanged(APIS.WITHDRAWAL)
            self.logger.info(user_info)
            amount = user_info.get("amount", 0)
            u_ali_account = user_info.get("u_ali_account")
            u_ali_real_name = user_info.get("u_ali_real_name")

        if amount < 30 or amount // 100 < self.withdraw:
            raise WithdrawFailed("ğŸ”´ æç°å¤±è´¥, å½“å‰è´¦æˆ·ä½™é¢è¾¾ä¸åˆ°æç°è¦æ±‚!")

        if self.withdraw_type == "wx":
            self.logger.info("å¼€å§‹è¿›è¡Œå¾®ä¿¡æç°æ“ä½œ...")
            self.__request_do_withdraw(amount, "wx")
        elif self.withdraw_type == "ali":
            self.logger.info("å¼€å§‹è¿›è¡Œæ”¯ä»˜å®æç°æ“ä½œ...")
            if u_ali_account is None or u_ali_real_name is None:
                u_ali_account = self.aliAccount
                u_ali_real_name = self.aliName

            if u_ali_account is None or u_ali_real_name is None:
                raise Exception("ğŸŸ¡ è¯·å…ˆé…ç½®æ”¯ä»˜å®è´¦å·ä¿¡æ¯ï¼Œå†è¿›è¡Œæç°æ“ä½œ!")

            self.__request_do_withdraw(
                amount,
                "ali",
                u_ali_account,
                u_ali_real_name
            )
        else:
            raise Exception(f"ğŸŸ¡ ä½œè€…ç›®å‰æš‚æœªé€‚é…æ­¤ã€{self.withdraw_type}ã€‘æç°æ–¹å¼!")

    def __request_do_withdraw(self, amount, _type, u_ali_account=None, u_ali_real_name=None):
        """
        å‘èµ·æç°è¯·æ±‚
        :return:
        """
        if u_ali_account is not None:
            data = {
                "amount": amount,
                "type": _type,
                "u_ali_account": u_ali_account,
                "u_ali_real_name": u_ali_real_name
            }

        else:
            data = {
                "amount": amount,
                "type": _type
            }

        withdraw_result: list | str = self.request_for_json(
            "POST",
            APIS.DO_WITHDRAWAL,
            "æç° base_client",
            client=self.base_client,
            data=data,
            # å¿½ç•¥jsonè§£æé”™è¯¯
            ignore_json_error=True,
            ret_types=RetTypes.TEXT
        )

        try:
            if isinstance(withdraw_result, list):
                withdraw_result: dict = withdraw_result[0]
            elif isinstance(withdraw_result, str):
                withdraw_result: str = re.sub(r"<pre>.*?</pre>", "", withdraw_result, flags=re.S)
                withdraw_result: dict = json.loads(withdraw_result)
            else:
                raise RspAPIChanged(APIS.DO_WITHDRAWAL)

            if withdraw_result['code'] == 0:
                self.logger.info(f"ğŸŸ¢ æç°æˆåŠŸ! é¢„è®¡åˆ°è´¦ {amount / 100} å…ƒ")
            else:
                self.logger.info(f"ğŸŸ¡ æç°å¤±è´¥ï¼ŒåŸå› ï¼š{withdraw_result['msg']}")
        except (json.JSONDecodeError, KeyError) as e:
            self.logger.exception(f"ğŸŸ¡ æç°å¤±è´¥ï¼ŒåŸå› ï¼š{e}ï¼ŒåŸå§‹æ•°æ®: {withdraw_result}")

    def __request_withdrawal_for_userinfo(self) -> RspWithdrawal | dict:
        """
        å‘èµ·ææ¬¾è¯·æ±‚ï¼Œä»è€Œè·å–ææ¬¾ç”¨æˆ·ä¿¡æ¯
        :return:
        """
        return self.request_for_json(
            "GET",
            APIS.WITHDRAWAL,
            "è·å–ææ¬¾ç”¨æˆ·ä¿¡æ¯ base_client",
            client=self.base_client,
            model=RspWithdrawal
        )

    def __pass_detect_and_read(self, part_api_path, full_api_path, *args, **kwargs):
        """
        å°è¯•é€šè¿‡æ£€æµ‹å¹¶ä¸”å¼€å§‹é˜…è¯»
        :param part_api_path: éƒ¨åˆ†apiè·¯å¾„
        :param full_api_path: åˆå§‹å®Œæ•´apiè·¯å¾„ï¼ˆåé¢ä¼šéšç€é˜…è¯»æ–‡ç« é“¾æ¥çš„ä¸åŒæ”¹å˜ï¼‰
        :return:
        """
        is_sleep = False
        is_need_push = False
        is_pushed = False
        retry_count = 2
        while True:
            res_model = self.__request_for_do_read_json(full_api_path, is_sleep=is_sleep, is_pushed=is_pushed)
            ret_count = res_model.ret_count
            if ret_count == 3 and res_model.jkey is None:
                # å¦‚æœæ˜¯3ä¸ªï¼Œä¸”æ²¡æœ‰jkeyè¿”å›ï¼Œåˆ™å¤§æ¦‚ç‡å°±æ˜¯æœªé€šè¿‡æ£€æµ‹
                if res_model.is_pass_failed:
                    raise FailedPassDetect()
                else:
                    raise FailedPassDetect("ğŸ”´ è²Œä¼¼æ£€æµ‹å¤±è´¥äº†ï¼Œå…·ä½“è¯·æŸ¥çœ‹ä¸Šæ–¹æŠ¥é”™åŸå› ")
            article_url = res_model.url
            if ret_count == 1 and article_url is None:
                if retry_count == 0:
                    raise NoSuchArticle("ğŸŸ¡ å½“å‰è´¦å·æ²¡æœ‰æ–‡ç« é“¾æ¥è¿”å›ï¼Œä¸ºé¿å…é»‘å·å’Œå°å·ï¼Œå·²åœæ­¢å½“å‰è´¦å·è¿è¡Œ")
                is_sleep = True
                if ret_count >= 0:
                    self.logger.war(f"ğŸŸ¡ è¿”å›çš„é˜…è¯»æ–‡ç« é“¾æ¥ä¸ºNone, å°è¯•é‡æ–°è¯·æ±‚")
                    retry_count -= 1
                    continue
                full_api_path = self.__build_do_read_url_path(
                    part_api_path,
                    jkey=res_model.jkey
                )
                # is_sleep = True
                # continue
            if article_url is None:
                raise ValueError(f"ğŸ”´ è¿”å›çš„é˜…è¯»æ–‡ç« é“¾æ¥ä¸ºNone, æˆ–è®¸APIå…³é”®å­—æ›´æ–°å•¦, å“åº”æ¨¡å‹ä¸ºï¼š{res_model}")

            if article_url == "close" and ret_count == 2:
                if "æœ¬è½®é˜…è¯»å·²å®Œæˆ" == res_model.success_msg:
                    self.logger.info(f"ğŸŸ¢âœ”ï¸ {res_model.success_msg}")
                    return
                raise FailedPassDetect(f"ğŸŸ¡ğŸ”´ {res_model.success_msg}")
                # elif res_model.msg is not None and "ä»Šå¤©å·²è¾¾åˆ°é˜…è¯»é™åˆ¶" in res_model.msg:
                #     raise FailedPassDetect("ğŸŸ¢â­•ï¸ æ­¤è´¦å·ä»Šå¤©å·²è¾¾åˆ°é˜…è¯»é™åˆ¶ï¼Œè¯·æ˜å¤©å†æ¥!")
                # elif "é˜…è¯»é™åˆ¶" in res_model.success_msg:
                #     raise FailedPassDetect(f"ğŸŸ¢â­•ï¸ {res_model.success_msg}")
                # elif "ä»»åŠ¡ä¸Šé™" in res_model.success_msg:
                #     raise FailedPassDetect(f"ğŸŸ¢â­•ï¸ {res_model.success_msg}")
                # elif res_model.is_pass_failed:
                #     raise FailedPassDetect("ğŸ”´â­•ï¸ æ­¤è´¦å·ä»Šæ—¥å·²è¢«æ ‡è®°ï¼Œè¯·æ˜å¤©å†è¯•!")
                #
                # else:
                #     raise FailedPassDetect(f"ğŸŸ¡ {res_model.success_msg}")

            biz_match = self.ARTICLE_BIZ_COMPILE.search(article_url)
            # åˆ¤æ–­é“¾æ¥ä¸­æ˜¯å¦åŒ…å«æ£€æµ‹ç‰¹å¾ï¼Œæˆ–è€…ä¸ç¬¦åˆæ­£å¸¸é˜…è¯»é“¾æ¥
            if "chksm" in article_url or not self.ARTICLE_LINK_VALID_COMPILE.match(article_url):
                self.logger.info(f"ğŸŸ¡ å‡ºç°åŒ…å«æ£€æµ‹ç‰¹å¾çš„æ–‡ç« é“¾æ¥ï¼Œèµ°æ¨é€é€šé“")
                is_need_push = True
            # åˆ¤æ–­æ˜¯å¦æå–bizæˆåŠŸï¼Œå¹¶ä¸”bizåŒ…å«åœ¨ç‰¹å¾bizä¸­
            elif biz_match and biz_match.group(1) in self.detected_biz_data:
                self.logger.info(f"ğŸŸ¡ å‡ºç°å·²è¢«æ ‡è®°çš„bizæ–‡ç« ï¼Œèµ°æ¨é€é€šé“")
                is_need_push = True
            # åˆ¤æ–­æ­¤æ¬¡è¯·æ±‚åè¿”å›çš„é”®å€¼å¯¹æ•°é‡æ˜¯å¤šå°‘
            # elif ret_count == 2:
            #
            #     is_need_push = True
            elif ret_count == 4:
                # è¡¨ç¤ºæ­£å¤„äºæ£€æµ‹ä¸­
                self.logger.info(f"ğŸŸ¡ æ­¤æ¬¡æ£€æµ‹ç»“æœä¸ºï¼š{res_model.success_msg}")
            #
            #     is_sleep = False
            #     is_need_push = True
            elif ret_count == 3 and res_model.jkey is not None:
                # å¦‚æœæ˜¯3ä¸ªï¼Œä¸”æœ‰jkeyè¿”å›ï¼Œåˆ™è¡¨ç¤ºå·²ç»é€šè¿‡æ£€æµ‹
                if "æˆåŠŸ" in res_model.success_msg:
                    self.logger.info(f"ğŸŸ¢âœ…ï¸ {res_model.success_msg}")
                else:
                    self.logger.info(f"ğŸŸ¢âŒï¸ {res_model.success_msg}")
                is_sleep = True
                # æ²¡æœ‰çœ‹åˆ°è¦ç”¨ä»€ä¹ˆï¼Œä½†æ˜¯æ¯æ¬¡do_readéƒ½ä¼šè¯·æ±‚2éï¼Œæ•…è¿™é‡Œä¹Ÿæ·»åŠ è°ƒç”¨
                time.sleep(random.randint(1, 3))
                self.__request_for_read_url()
                time.sleep(random.randint(1, 3))
                self.__request_for_read_url()
            else:
                is_sleep = True

            # æ‰“å°æ–‡ç« å†…å®¹
            self.__print_article_info(res_model.url)

            if is_need_push:
                is_pushed = self.wx_pusher_link(res_model.url)
                if not is_pushed:
                    raise FailedPushTooManyTimes()
                is_need_push = False
                is_sleep = True
            else:
                is_pushed = False

            # é‡æ–°æ„å»º full_api_path
            full_api_path = self.__build_do_read_url_path(
                part_api_path,
                jkey=res_model.jkey
            )

    def __print_article_info(self, article_url):
        """
        è§£ææ–‡ç« ä¿¡æ¯
        :param article_url: æ–‡ç« é“¾æ¥
        :return:
        """
        try:
            # è·å–æ–‡ç« æºä»£ç 
            article_page = self.__request_article_page(article_url)
        except:
            article_page = ""

        if r := self.ARTICLE_BIZ_COMPILE.search(article_page):
            article_biz = r.group(1)
        else:
            article_biz = ""
        if r := self.ARTICLE_TITLE_COMPILE.search(article_page):
            article_title = r.group(1)
        else:
            article_title = ""
        if r := self.ARTICLE_AUTHOR_COMPILE.search(article_page):
            article_author = r.group(1)
        else:
            article_author = ""
        if r := self.ARTICLE_DESC_COMPILE.search(article_page):
            article_desc = r.group(1)
        else:
            article_desc = ""
        self.logger.info(ArticleInfo(
            article_url=article_url,
            article_biz=article_biz,
            article_title=article_title,
            article_author=article_author,
            article_desc=article_desc
        ))

    def __request_article_page(self, article_url: str):
        return self.request_for_page(article_url, "è¯·æ±‚æ–‡ç« ä¿¡æ¯ article_client", client=self.article_client)

    def __request_for_do_read_json(self, do_read_full_path: str, is_pushed: bool = False,
                                   is_sleep: bool = True) -> RspDoRead | dict:

        if is_sleep:
            t = self.push_delay[0] if is_pushed else random.randint(self.read_delay[0], self.read_delay[1])
            self.logger.info(f"ç­‰å¾…æ£€æµ‹å®Œæˆ, ğŸ’¤ ç¡çœ {t}ç§’" if is_pushed else f"ğŸ’¤ éšæœºç¡çœ {t}ç§’")
            # ç¡çœ éšæœºæ—¶é—´
            time.sleep(t)
        else:
            time.sleep(1)

        ret = self.request_for_json(
            "GET",
            do_read_full_path,
            "è¯·æ±‚do_read read_client",
            client=self.read_client,
            model=RspDoRead
        )
        # # åªè¦æ¥å£å“åº”æ•°æ®ä¸æ”¹å˜ï¼Œé‚£ä¹ˆè¿”å›çš„æ ¼å¼å°±ä¸€å®šä¼šæ˜¯RspDoRead
        # if isinstance(ret, dict):
        #     # ä»¥é˜²ä¸‡ä¸€ï¼Œè¿™é‡Œè¿˜æ˜¯å°½é‡åšä¸€ä¸‹è½¬æ¢
        #     ret = RspDoRead(jkey=ret["jkey"], url=ret["url"])
        return ret

    def __build_do_read_url_path(self, do_read_url_part_path: str, **params) -> str:
        """æ„å»ºå®Œæˆé˜…è¯»çš„å®Œæ•´è·¯å¾„ï¼ˆåŒ…æ‹¬å‚æ•°ï¼‰"""
        ret = [do_read_url_part_path, "pageshow", f"r={random.random()}", f"iu={self.iu}"]
        for k, v in params.items():
            ret.append(f"{k}={v}")
        return "&".join(ret)

    def __parse_r_js_code(self, r_js_code: str, *params) -> str:
        """
        è§£ær.jsä»£ç 
        :param r_js_code: r.jsä»£ç 
        :return: ä¸‹ä¸€é˜¶æ®µçš„è¯·æ±‚é“¾æ¥è·¯å¾„
        """
        if r := self.R_JS_CODE_COMPILE.search(r_js_code):
            return f"{r.group(1)}{params[0]}{r.group(2)}{params[1]}"
        else:
            raise RegExpError(self.R_JS_CODE_COMPILE)

    def __request_r_js_code(self, r_js_path: str) -> str:
        """è¯·æ±‚r.jsæ–‡ä»¶ä»£ç """
        return self.request_for_page(
            r_js_path,
            "è¯·æ±‚r.jsæºä»£ç , read_client",
            client=self.read_client,
            update_headers={
                "Referer": self.load_page_url.__str__(),
            }
        )

    def __parse_read_load_page(self, read_load_page_html: str) -> tuple:
        """
        è§£ææ­£åœ¨åŠ è½½é¡µé¢æºä»£ç ï¼Œæå–éœ€è¦çš„æ•°æ®
        :param read_load_page_html:
        :return:
        """
        if r := self.READ_LOAD_PAGE_COMPILE.search(read_load_page_html):
            # å¥½åƒç™½å†™é‚£ä¹ˆé•¿çš„æ­£åˆ™äº†ï¼Œè¿™ä¸ªæºä»£ç ä¸­çš„å†…å®¹å†å…¶ä»–æ•°æ®åŒ…ä¸­ç”¨çš„ä¸å¤š...
            # ç®—äº†æ‡’å¾—æ”¹äº†
            forstr = r.group(1)
            zs = r.group(2)
            # url = f"{r.group(4)}{forstr}{r.group(5)}{zs}"
            self.iu = r.group(3)
            r_js_path = r.group(6)
            r_js_version = r.group(7)
            return forstr, zs, r_js_path, r_js_version
        else:
            raise RegExpError(self.READ_LOAD_PAGE_COMPILE)

    def __request_for_read_load_page(self, read_url: URL) -> str:
        """
        è¯·æ±‚æ­£åœ¨åŠ è½½é¡µé¢
        :param read_url:
        :return:
        """
        return self.request_for_page(
            read_url,
            "è¯·æ±‚é˜…è¯»åŠ è½½é¡µé¢ base_client",
            client=self.read_client
        )

    def __print_recommend_data(self, recommend_data: RspRecommend | dict):
        """
        æ‰“å°æ¨èæ•°æ®
        :param recommend_data:
        :return:
        """
        # åˆ¤æ–­æ˜¯å¦æ˜¯é¢„æœŸæ¨¡å‹
        if isinstance(recommend_data, RspRecommend):
            self.logger.info(recommend_data.data.user)
            infoView = recommend_data.data.infoView
            self.logger.info(infoView)
            if msg := infoView.msg:
                if "ä¸‹ä¸€æ‰¹" in msg:
                    raise PauseReadingWaitNext(msg)
                elif "é˜…è¯»é™åˆ¶" in msg or "ä»»åŠ¡ä¸Šé™" in msg:
                    raise StopReadingNotExit(msg)

    def __request_for_read_url(self) -> URL:
        """
        è·å–é˜…è¯»é“¾æ¥
        :return:
        """
        data: RspReadUrl | dict = self.request_for_json(
            "GET",
            APIS.GET_READ_URL,
            "è¯·æ±‚é˜…è¯»é“¾æ¥ base_client",
            model=RspReadUrl,
            client=self.base_client
        )
        if isinstance(data, RspReadUrl):
            return data.link
        try:
            # æœ‰æ—¶ä¼šè¿”å›è¿™ä¸ª { "reload": 1 }ï¼Œå¤§æ¦‚ç‡Cookieæ˜¯ä»PCå¾®ä¿¡ä¸ŠæŠ“å–çš„
            if data.get('reload') == 1:
                raise CookieExpired()
            return data['jump']
        except KeyError:
            raise RspAPIChanged(APIS.GET_READ_URL)

    def __request_recommend_json(self, referer: URL) -> RspRecommend | dict:
        """
        è·å–æ¨èæ•°æ®
        :return:
        """
        recommend_data = self.request_for_json("GET", APIS.RECOMMEND, "è¯·æ±‚æ¨èæ•°æ® base_client", update_headers={
            "Referer": referer.__str__()
        }, model=RspRecommend, client=self.base_client)

        return recommend_data

    def __request_redirect_for_redirect(self) -> URL:
        """
        è¯·æ±‚å…¥å£é“¾æ¥è¿”å›çš„é‡å®šå‘é“¾æ¥ï¼ˆè¿™ä¸ªé“¾æ¥ç”¨æ¥è·å–é¦–é¡µæºä»£ç ï¼‰
        :return:
        """
        self.base_client.cookies = self.cookie_dict
        return self.request_for_redirect(self.base_full_url, "è¯·æ±‚å…¥å£é“¾æ¥è¿”å›çš„é‡å®šå‘é“¾æ¥", client=self.base_client)

    def __request_entry_for_redirect(self) -> URL:
        """
        è¯·æ±‚å…¥å£é“¾æ¥ï¼Œä»è€Œè·å–é‡å®šå‘é“¾æ¥
        :return:
        """
        return self.request_for_redirect(self.entry_url, "è¯·æ±‚å…¥å£é“¾æ¥ï¼Œ main_client", client=self.main_client)

    @property
    def withdraw_type(self):
        """
        æç°æ–¹å¼ é»˜è®¤å¾®ä¿¡æç°
        :return:
        """
        ret = self.account_config.withdraw_type
        if ret is None:
            ret = self.config_data.withdraw_type
        return ret if ret is not None else "wx"

    @property
    def iu(self):
        return self._cache.get(f"iu_{self.ident}")

    @iu.setter
    def iu(self, value):
        self._cache[f"iu_{self.ident}"] = value

    @property
    def load_page_url(self):
        return self._cache.get(f"load_page_url_{self.ident}")

    @load_page_url.setter
    def load_page_url(self, value):
        self._cache[f"load_page_url_{self.ident}"] = value


if __name__ == '__main__':
    KLYDV2()
