# -*- coding: utf-8 -*-
# yryd.py created by MoMingLog on 3/4/2024.
"""
ã€ä½œè€…ã€‘MoMingLog
ã€åˆ›å»ºæ—¶é—´ã€‘2024-04-03
ã€åŠŸèƒ½æè¿°ã€‘
"""
import random
import re
import time
from urllib.parse import unquote_plus

from httpx import URL

from config import load_yryd_config
from exception.common import Exit, StopReadingNotExit, RegExpError, ExitWithCodeChange, PauseReadingTurnNext, \
    FailedPushTooManyTimes, CookieExpired
from schema.yryd import YRYDConfig, RspReadUrl, RspDoRead
from script.common.base import WxReadTaskBase, RetTypes
from utils import EntryUrl


class APIS:
    # API: é˜…è¯»ï¼ˆæ‰«ç åè·³è½¬çš„é“¾æ¥ï¼‰ - ç¨‹åºè‡ªåŠ¨æå–
    GET_READ_URL = "/read_task/gru"
    # API: do_readï¼ˆç›®å‰é»˜è®¤æ˜¯è¿™ä¸ªï¼‰ - ç¨‹åºè‡ªåŠ¨æå–
    DO_READ = "/read_task/do_read"
    # API: ææ¬¾é¡µé¢
    WITHDRAWAL = "/withdrawal"
    # API: ææ¬¾è¯·æ±‚
    DO_WITHDRAW = "/withdrawal/submit_withdraw"


class YRYDV2(WxReadTaskBase):
    # å½“å‰è„šæœ¬ä½œè€…
    CURRENT_SCRIPT_AUTHOR = "MoMingLog"
    # å½“å‰è„šæœ¬ç‰ˆæœ¬
    CURRENT_SCRIPT_VERSION = "2.0.1"
    # å½“å‰è„šæœ¬åˆ›å»ºæ—¶é—´
    CURRENT_SCRIPT_CREATED = "2024-04-03"
    # å½“å‰è„šæœ¬æ›´æ–°æ—¶é—´
    CURRENT_SCRIPT_UPDATED = "2024-04-08"
    # å½“å‰ä»»åŠ¡åç§°
    CURRENT_TASK_NAME = "é±¼å„¿é˜…è¯»"

    # æå–ä¸»é¡µæºä»£ç ä¸­çš„é˜…è¯»æƒ…å†µï¼ˆç›®å‰ä»…æå–IDã€ä½™é¢ã€å·²è¯»ç¯‡æ•°ã€é˜…è¯»è§„åˆ™ã€æ‰«ç åè·³è½¬çš„APIã€è·å–æˆåŠŸé˜…è¯»é“¾æ¥åçš„typeå‚æ•°ï¼‰
    HOMEPAGE_COMPILE = re.compile(
        r"<p.*?>ã€ID:(.*?)ã€‘ä½™é¢.*?(\d+\.*\d*)å…ƒ.*?p>ä»Šæ—¥å·²è¯»(\d+)ç¯‡[,ï¼Œ].*?</p>.*?p.*?>(æ¯å°æ—¶.*?)</p>.*?show_qrcode.*?is_make_qrcode.*?get\(['\"](.*?)['\"].*?var.*?['\"]&type=(\d+)['\"]",
        re.S)
    # åˆ¤æ–­æ˜¯å¦æ˜¯é“¾æ¥æ ¼å¼
    LINK_MATCH_COMPILE = re.compile(r"^https?://[^\s/$.?#].\S*$")
    # æå–é˜…è¯»è·³è½¬ä¸»é¡µä¸­çš„æ•°æ®ï¼ˆdo_read APIã€do_readéƒ¨åˆ†å‚æ•°ã€éƒ¨åˆ†å‚æ•°éšæœºæ•°ç‰¹å¾ï¼‰
    LOADING_PAGE_COMPILE = re.compile(r"script.*?url\s*=\s*['\"](.*?)['\"].*?åŠ è½½ä¸­.*?get\(.*?['\"](.*?)['\"](.*?)\)",
                                      re.S)
    # æå–ææ¬¾ç•Œé¢çš„åŸæœ‰æ”¯ä»˜å®è´¦å·
    WITHDRAWAL_PAGE_COMPILE = re.compile(r"id=['\"](?:u_ali_real_name|u_ali_account).*?value=['\"](.*?)['\"]", re.S)
    # ææ¬¾ç•Œé¢çš„å½“å‰ä½™é¢
    CURRENT_GOLD_COMPILE = re.compile(r"å½“å‰ä½™é¢.*?>(\d+\.?\d*)<", re.S)

    def __init__(self, config_data: YRYDConfig = load_yryd_config(), run_read_task: bool = True):
        self.run_read_task = run_read_task
        self.homepage_api = None
        self.main_thread_ident = self.ident
        self.detected_biz_data = config_data.biz_data or []
        super().__init__(config_data, logger_name="ğŸŸï¸é˜…è¯»", load_detected=True)

    def get_entry_url(self):
        return EntryUrl.get_yryd_entry_url()

    def init_fields(self, retry_count=3):
        # åœ¨ä¸»çº¿ç¨‹ä¸­å…ˆåˆ¤æ–­å…¥å£é“¾æ¥æ˜¯å¦è·å–æˆåŠŸ
        if self.entry_url is None:
            raise Exit("å…¥å£é“¾æ¥ä¸ºç©º!")
        # åˆå§‹åŒ– main_client
        self.parse_base_url(self.entry_url, self.main_client)
        # å¯¹å…¥å£é“¾æ¥å‘èµ·è¯·æ±‚ï¼Œè·å–é‡å®šå‘é“¾æ¥
        redirect_url = self.request_for_redirect(
            self.entry_url,
            "è¯·æ±‚å…¥å£é“¾æ¥ main_client",
            client=self.main_client
        )
        self.logger.debug(f"ç¬¬ä¸€æ¬¡é‡å®šå‘é“¾æ¥: {redirect_url}")
        # å¯¹é‡å®šå‘åçš„é“¾æ¥å‘èµ·è¯·æ±‚ï¼Œè·å–äºŒæ¬¡é‡å®šå‘é“¾æ¥
        redirect_url = self.request_for_redirect(
            redirect_url,
            "äºŒæ¬¡é‡å®šå‘ main_client",
            client=self.main_client
        )
        self.logger.debug(f"äºŒæ¬¡é‡å®šå‘é“¾æ¥ä¸ºï¼š{redirect_url}")
        # å¼€å§‹æå–äºŒæ¬¡é‡å®šå‘é“¾æ¥ä¸­çš„å‚æ•°å€¼
        # å…ˆè½¬æˆ URL ç±»å‹
        url_params = URL(redirect_url).params
        # æå–é“¾æ¥ä¸­çš„é‡å®šå‘é“¾æ¥
        redirect_url = URL(url_params.get("redirect_uri", ""))
        # å‚¨å­˜ä¸€ä¸‹æ³¨æ„API
        self.homepage_api = redirect_url.params.get("redirect")
        # å†æ¬¡æ›´æ–° main_client
        self.parse_base_url(redirect_url, self.main_client)

    def run(self, name, *args, **kwargs):
        self.base_client.base_url = self.main_client.base_url
        self.read_client.base_url = self.main_client.base_url
        # åˆ¤æ–­ cookieä¸­æ˜¯å¦æœ‰ PHPSESSID
        if "PHPSESSID" in self.origin_cookie:
            # å†ä¸ºå½“å‰ç”¨æˆ·æ›´æ–°å¯¹åº”é…ç½®çš„cookie
            self.read_client.cookies = self.cookie_dict
            self.base_client.cookies = self.cookie_dict
            self.entry_func_for_cookie()
        else:
            self.read_client.headers.update({
                "Cookie": self.origin_cookie
            })
            self.base_client.headers.update({
                "Cookie": self.origin_cookie
            })
            self.entry_func_for_id()

    def entry_func_for_id(self):
        """
        ä½¿ç”¨IDè¿›è¡Œé˜…è¯»çš„å…¥å£å‡½æ•°
        :return:
        """
        # æ‹¼æ¥è·å–é˜…è¯»é“¾æ¥çš„URL
        api_path = f"{APIS.GET_READ_URL}?iu=iuMjA2ODc0OQ2"
        # read_url_model = self.__request_read_url(api_path)
        # self.logger.info(read_url_model)
        self.logger.war("ğŸŸ¡ å½“å‰æ­£åœ¨é€šè¿‡IDè¿›è¡Œé˜…è¯»æ“ä½œï¼ˆIDæ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯å’Œæç°, åªèƒ½è¿›è¡Œé˜…è¯»æ“ä½œï¼‰...")
        self.logger.war("ğŸŸ¡ ç”±äºæ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯ï¼Œæ•…æ¯æ¬¡è¿è¡Œé»˜è®¤ä¸ºç¬¬1è½®ç¬¬1ç¯‡!")
        time.sleep(5)
        self.current_read_count = 0
        self.__start_read(turn_count=1, read_url_api_path=api_path)

    def entry_func_for_cookie(self):
        """
        ä½¿ç”¨Cookieè¿›è¡Œé˜…è¯»çš„å…¥å£å‡½æ•°
        :return:
        """
        # å°è¯•è·å–ä¸»é¡µæºä»£ç 
        homepage_html = self.request_for_page(
            self.homepage_api,
            "è¯·æ±‚ä¸»é¡µæºä»£ç  read_client",
            client=self.read_client
        )
        if not homepage_html:
            raise CookieExpired()

        if r := self.HOMEPAGE_COMPILE.search(homepage_html):
            self.current_read_count = int(r.group(3))
            self.logger.info("\n".join([
                "ã€ç”¨æˆ·æ•°æ®ã€‘",
                f"> ç”¨æˆ· ID: {r.group(1)}",
                f"> å½“å‰ä½™é¢: {r.group(2)}",
                f"> ä»Šæ—¥å·²è¯»: {self.current_read_count}",
                f"> é˜…è¯»è§„åˆ™: {r.group(4)}"
            ]))

            if not self.run_read_task:
                self.__request_withdraw()
                return

            # è¦†ç›–åŸAPI
            APIS.GET_READ_URL = r.group(5)
            _type = r.group(6)
            turn_count = self.current_read_count // 30 + 1
            self.logger.war(f"ğŸŸ¡ å½“å‰æ˜¯ç¬¬[{turn_count}]è½®é˜…è¯»")
            self.__start_read(_type, turn_count)
            self.__request_withdraw()
        else:
            raise RegExpError(self.HOMEPAGE_COMPILE)

    def __start_read(self, _type=7, turn_count=None, retry: int = 3, read_url_api_path: str = None):
        self.logger.war("ğŸŸ¡ æ­£åœ¨è·å–é˜…è¯»é“¾æ¥...")
        read_url_model = self.__request_read_url(read_url_api_path)
        # è·å–é˜…è¯»åŠ è½½é¡µé“¾æ¥
        read_url: URL = self.__get_read_url(read_url_model)

        # æ„å»ºå®Œæ•´é˜…è¯»é“¾æ¥
        full_read_url = f"{read_url}&type={_type}"
        # æ›´æ–°read_clientè¯·æ±‚å¤´
        self.read_client.headers.update({
            "Referer": full_read_url
        })

        read_count = self.current_read_count % 30 + 1
        jkey = None
        use_user_cookie = False
        article_map = {}
        while True:
            # è¯·æ±‚åŠ è½½é¡µæºä»£ç 
            loading_page = self.__request_loading_page(full_read_url, use_user_cookie)
            # æ­£åˆ™åŒ¹é…æå–ç›¸å…³éœ€è¦å‚æ•°
            if r2 := self.LOADING_PAGE_COMPILE.search(loading_page):
                # ä»¥é˜²ä¸‡ä¸€åˆ¤æ–­ä¸‹ r å‚æ•°çš„å€¼æ˜¯å¦ä¸º éšæœºæ•°
                if "Math.random" in r2.group(3):
                    # è¦†ç›–åŸAPIï¼ˆé™„å¸¦å‚æ•°ï¼‰
                    APIS.DO_READ = f"{r2.group(1)}?iu={self.iu}&type={_type}{r2.group(2)}{random.random()}"
                    # åˆ¤æ–­jkeyæ˜¯å¦å·²å¡«å……
                    if jkey is not None:
                        APIS.DO_READ = f"{APIS.DO_READ}&jkey={jkey}"
                    # å‘èµ· å®Œæˆé˜…è¯» è¯·æ±‚
                    do_read_model = self.__request_do_read()
                    # åˆ¤æ–­æ˜¯å¦è½¬æ¢æ¨¡å‹æˆåŠŸï¼Œå¹¶ä¸”article_urlå­˜åœ¨
                    if isinstance(do_read_model, RspDoRead) and (article_url := do_read_model.url):
                        unquote_url = unquote_plus(article_url)
                        # åˆ¤æ–­å½“å‰é˜…è¯»é“¾æ¥æ˜¯å¦å·²ç»å¤±æ•ˆ
                        if "é“¾æ¥å¤±æ•ˆ" in unquote_url:
                            # åˆ¤æ–­å½“å‰é€’å½’é‡è¯•æ¬¡æ•°æ˜¯å¦å¤§äº0
                            if retry > 0:
                                # é‡è¯•æ¬¡æ•°è‡ªå‡1
                                retry -= 1
                                self.logger.war(f"ğŸŸ¡ é˜…è¯»é“¾æ¥å·²å¤±æ•ˆ! å°è¯•é‡æ–°è·å–, å‰©ä½™å°è¯•æ¬¡æ•°: {retry}")
                                # é€’å½’è°ƒç”¨
                                # å…ˆéšæœºç¡çœ 1-3ç§’
                                time.sleep(random.randint(1, 3))
                                self.__start_read(_type, retry)
                            else:
                                # é‡è¯•æ¬¡æ•°å·²å½’é›¶åˆ™æŠ›å‡ºå¼‚å¸¸
                                raise PauseReadingTurnNext("é‡æ–°è·å–é˜…è¯»é“¾æ¥æ¬¡æ•°å·²ç”¨å°½!")
                        elif "å½“å‰å·²ç»è¢«é™åˆ¶" in unquote_url:
                            last_article_url = article_map.get(f"{turn_count} - {read_count - 1}", "")
                            if last_article_url:
                                self.new_detected_data.add(last_article_url)
                            self.logger.error("ğŸ”´ å½“å‰å·²ç»è¢«é™åˆ¶ï¼Œè¯·æ˜å¤©å†æ¥")
                            return
                        elif "/finish?" in unquote_url:
                            self.logger.war(f"ğŸŸ¡ æœ¬è½®é˜…è¯»ä»»åŠ¡å¯èƒ½å·²ç»å®Œæˆ, å“åº”é“¾æ¥: {unquote_url}")
                            return
                        # æ›´æ–°ä¸‹ä¸€æ¬¡ do_read é“¾æ¥çš„ jkey å‚æ•°
                        jkey = do_read_model.jkey
                        # é¡ºä¾¿å°†è¯·æ±‚åŠ è½½é¡µæºä»£ç çš„ä½¿ç”¨ç”¨æˆ·cookieæ‰“å¼€
                        use_user_cookie = True
                        # æ‰“å°é˜…è¯»æƒ…å†µ
                        if self.current_read_count != 0:
                            msg = f"ğŸŸ¡ å‡†å¤‡é˜…è¯»ç¬¬[{turn_count} - {read_count}]ç¯‡, å·²æˆåŠŸé˜…è¯»[{self.current_read_count}]ç¯‡"
                        else:
                            msg = f"ğŸŸ¡ å‡†å¤‡é˜…è¯»[{turn_count} - {read_count}]ç¯‡"
                        self.logger.war(msg)

                        self.logger.info(
                            f"ã€ç¬¬ [{turn_count} - {read_count}] ç¯‡æ–‡ç« ä¿¡æ¯ã€‘\n{self.parse_wx_article(article_url)}")

                        article_map[f"{turn_count} - {read_count}"] = article_url

                        self.__check_article_url(article_url, turn_count, read_count)
                        # æ— æ³•åˆ¤æ–­æ˜¯å¦é˜…è¯»æˆåŠŸï¼Œè‚¡è¿™é‡Œç›´æ¥è‡ªå¢
                        read_count += 1
                        self.current_read_count += 1
                    else:
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œé‚£ä¹ˆæ­¤æ—¶è¯´æ˜è¿”å›çš„æ•°æ®æ˜¯å­—å…¸ç±»å‹
                        # è¿™é‡Œç›®å‰æš‚ä¸æ‰“ç®—é€‚é…
                        # self.logger.war("")
                        pass
                else:
                    # æ¥å£å‚æ•°å‘ç”Ÿå˜åŒ–ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise ExitWithCodeChange(APIS.DO_READ)
            else:
                # æ­£åˆ™åŒ¹é…å¤±è´¥ï¼Œéœ€è¦æ›´æ–°äº†ï¼Œæ­¤æ—¶ä¹Ÿæœ‰å¯èƒ½æ˜¯æºä»£ç æ›´æ–°
                raise RegExpError(self.LOADING_PAGE_COMPILE)

    def __check_article_url(self, article_url, turn_count, read_count):
        is_pushed = False
        # æå–é“¾æ¥biz
        biz_match = self.NORMAL_LINK_BIZ_COMPILE.search(article_url)
        is_need_push = False
        # åˆ¤æ–­ä¸‹ä¸€ç¯‡é˜…è¯»è®¡æ•°æ˜¯å¦è¾¾åˆ°æŒ‡å®šæ£€æµ‹æ•°
        if self.current_read_count + 1 in self.custom_detected_count:
            self.logger.war(f"ğŸŸ¡ è¾¾åˆ°è‡ªå®šä¹‰è®¡æ•°æ•°é‡ï¼Œèµ°æ¨é€é€šé“!")
            is_need_push = True
            # åˆ¤æ–­æ˜¯å¦æ˜¯æ£€æµ‹æ–‡ç« 
        elif article_url in self.detected_data or article_url in self.new_detected_data:
            self.logger.war(f"ğŸŸ¡ å‡ºç°è¢«æ ‡è®°çš„æ–‡ç« é“¾æ¥, èµ°æ¨é€é€šé“!")
            is_need_push = True
        # åˆ¤æ–­æ˜¯å¦æ˜¯æ£€æµ‹æ–‡ç« 
        elif "chksm" in article_url or not self.ARTICLE_LINK_VALID_COMPILE.match(article_url):
            self.logger.war(f"ğŸŸ¡ å‡ºç°åŒ…å«æ£€æµ‹ç‰¹å¾çš„æ–‡ç« é“¾æ¥ï¼Œèµ°æ¨é€é€šé“!")
            is_need_push = True
        # åˆ¤æ–­æ˜¯å¦æ˜¯æ£€æµ‹æ–‡ç« 
        elif biz_match and biz_match.group(1) in self.detected_biz_data:
            self.logger.war(f"ğŸŸ¡ å‡ºç°å·²è¢«æ ‡è®°çš„bizæ–‡ç« ï¼Œèµ°æ¨é€é€šé“!")
            is_need_push = True
        if is_need_push:
            push_types = self.push_types
            push_result = []
            if 1 in push_types:
                push_result.append(self.wx_pusher(article_url, detecting_count=read_count))
            if 2 in push_types:
                push_result.append(self.wx_business_pusher(
                    article_url,
                    detecting_count=read_count,
                    situation=(
                        self.logger.name, turn_count, read_count - 1, self.current_read_count, read_count),
                    tips=f"è¯·å°½å¿«åœ¨æŒ‡å®šæ—¶é—´{self.push_delay[0]}ç§’å†…é˜…è¯»å®Œæ­¤ç¯‡æ–‡ç« "
                ))

            # åªè¦å…¶ä¸­ä»»æ„ä¸€ä¸ªæ¨é€æˆåŠŸï¼Œåˆ™èµ‹å€¼ä¸ºTrue
            is_pushed = any(push_result)
            # å¦‚æœæ¨é€å¤±è´¥
            if not is_pushed:
                # ç›´æ¥æŠ›å‡ºå¼‚å¸¸
                raise FailedPushTooManyTimes()
        self.sleep_fun(is_pushed)
        return is_need_push

    def __request_withdraw(self):
        # åˆ¤æ–­æ˜¯å¦è¦è¿›è¡Œæç°æ“ä½œ
        if not self.is_withdraw:
            self.logger.war(f"ğŸŸ¡ æç°å¼€å…³å·²å…³é—­ï¼Œå·²åœæ­¢æç°ä»»åŠ¡")
            return
        # å…ˆè¯·æ±‚æç°é¡µé¢
        withdrawal_page = self.__request_withdrawal_page()

        if money_match := self.CURRENT_GOLD_COMPILE.search(withdrawal_page):
            money = money_match.group(1)
        else:
            raise RegExpError(self.CURRENT_GOLD_COMPILE)

        if float(money) / 100 < self.withdraw:
            self.logger.war(f"ğŸŸ¡ è´¦æˆ·ä½™é¢ [{float(money) / 100}] ä¸è¶³ [{self.withdraw}]ï¼Œæ— æ³•æç°")
            return

        if self.withdraw_type == "wx":
            withdraw_result = self.__request_do_withdrawal(money)
        else:
            if self.aliName and self.aliAccount:
                u_ali_account = self.aliAccount
                u_ali_real_name = self.aliName
            else:
                if r := self.WITHDRAWAL_PAGE_COMPILE.findall(withdrawal_page):
                    if len(r) == 2:
                        u_ali_account = r[0]
                        u_ali_real_name = r[1]
                    else:
                        raise RegExpError(self.WITHDRAWAL_PAGE_COMPILE)
                else:
                    raise RegExpError(self.WITHDRAWAL_PAGE_COMPILE)

            withdraw_result = self.__request_do_withdrawal(money, u_ali_account, u_ali_real_name)

        if isinstance(withdraw_result, list):
            withdraw_result: dict = withdraw_result[0]
        msg = withdraw_result.get("msg", "")
        if "æç°æˆåŠŸ" in msg:
            self.logger.info(f"ğŸŸ¢ {msg}")
        else:
            self.logger.error(f"ğŸ”´ {msg}")

    def __request_do_withdrawal(self, money: float, u_ali_account=None, u_ali_real_name=None):

        if u_ali_account is None and u_ali_real_name is None:
            data = {
                "channel": "wechat",
                "money": money
            }
        else:
            data = {
                "channel": "alipay",
                "money": money,
                "u_ali_account": u_ali_account,
                "u_ali_real_name": u_ali_real_name
            }

        return self.request_for_json(
            "POST",
            APIS.DO_WITHDRAW,
            "è¯·æ±‚æç°è¯·æ±‚ base_client",
            client=self.base_client,
            update_headers={
                "Accept": "*/*",
                "Origin": self.base_client.base_url.__str__(),
                "Referer": f"{self.base_client.base_url}{APIS.WITHDRAWAL}",
                "X-Requested-With": "XMLHttpRequest"
            },
            data=data,
            # å¿½ç•¥jsonè§£æé”™è¯¯
            ignore_json_error=True,
            ret_types=RetTypes.TEXT
        )

    def __request_withdrawal_page(self):
        return self.request_for_page(
            APIS.WITHDRAWAL,
            "è¯·æ±‚æç°é¡µ base_client",
            client=self.base_client,
            update_headers={
                "X-Requested-With": "com.tencent.mm"
            }
        )

    def __request_do_read(self) -> RspDoRead | dict:
        return self.request_for_json(
            "GET",
            APIS.DO_READ,
            "å®Œæˆé˜…è¯»è¯·æ±‚ read_client",
            client=self.read_client,
            model=RspDoRead,
            update_headers={
                "Accept": "*/*"
            }
        )

    def __request_loading_page(self, read_url, use_user_cookie=False):
        """ä½¿ç”¨ä¸åŒ…å«ç”¨æˆ·cookieçš„å®¢æˆ·ç«¯è¯·æ±‚åŠ è½½é¡µæºä»£ç """
        return self.request_for_page(
            read_url,
            "è¯·æ±‚é˜…è¯»åŠ è½½é¡µ read_client",
            client=self.main_client if not use_user_cookie else self.read_client
        )

    def __get_read_url(self, read_url_model) -> URL:
        """
        è·å–é˜…è¯»é“¾æ¥
        :return:
        """
        read_url = None

        if isinstance(read_url_model, RspReadUrl) and (read_url := read_url_model.jump):
            self.logger.info(f"ğŸŸ¢ è·å–æˆåŠŸ [10åˆ†é’Ÿå†…å‹¿åˆ†äº«] -> {read_url}")
            read_url = URL(read_url)
        else:
            # å¦‚æœæ¨¡å‹åŒ¹é…å¤±è´¥ï¼Œåˆ™å°è¯•è‡ªåŠ¨æå–é˜…è¯»é“¾æ¥
            for value in read_url_model.values():
                if self.LINK_MATCH_COMPILE.match(value) and "iu" in value:
                    self.logger.info(f"ğŸŸ¢ è·å–æˆåŠŸ [10åˆ†é’Ÿå†…å‹¿åˆ†äº«] -> {value}")
                    read_url = URL(value)
                    break
        if read_url:
            # ä»read_urlä¸­æå–å‡ºiuå€¼å¹¶ç¼“å­˜
            self.iu = read_url.params.get("iu")
            # é¡ºæ‰‹æŠŠ read_client çš„ æ›´æ–°ä¸‹
            self.parse_base_url(read_url, client=self.read_client)
            return read_url
        else:
            raise StopReadingNotExit("é˜…è¯»é“¾æ¥è·å–å¤±è´¥!")

    def __request_read_url(self, api_path: str = None) -> RspReadUrl | dict:

        return self.request_for_json(
            "GET",
            APIS.GET_READ_URL if api_path is None else api_path,
            "è¯·æ±‚é˜…è¯»é“¾æ¥ read_client",
            client=self.read_client,
            model=RspReadUrl,
            update_headers={
                "X-Requested-With": "XMLHttpRequest",
                "Accept": "*/*"
            }
        )

    @property
    def withdraw_type(self):
        ret = self.account_config.withdraw_type
        if ret is None:
            ret = self.config_data.withdraw_type
        return ret if ret is not None else "wx"

    @property
    def iu(self):
        return self._cache.get(f"iu_{self.ident}")

    @iu.setter
    def iu(self, value):
        self._cache[f"iu_{self.ident}"] = value


if __name__ == '__main__':
    YRYDV2()
